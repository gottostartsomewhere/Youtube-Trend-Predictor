{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oRwbbWO0BwnU"
      },
      "outputs": [],
      "source": [
        "# YouTube Trend Prediction System\n",
        "# This code predicts the trending potential of a YouTube video based on its title, description, and tags\n",
        "# It also provides recommendations to improve the video's chances of trending\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import xgboost as xgb\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from collections import Counter\n",
        "import string\n",
        "import joblib\n",
        "import warnings\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import gensim.downloader as api\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTb7JKejB96j",
        "outputId": "8217df17-2838-43d3-e1e3-dc3d44ff5455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wr1xsQgB_rj",
        "outputId": "27538697-3c58-4b11-9622-6eb3bc741850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocessing data...\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing\n",
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        if text == '[none]' or pd.isna(text):\n",
        "            return ''\n",
        "\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove punctuation and special characters\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "        # Remove numbers\n",
        "        text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "        # Remove extra whitespaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Remove stopwords and lemmatize\n",
        "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens if word not in self.stop_words and len(word) > 2]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def process_tags(self, tags):\n",
        "        if tags == '[none]' or pd.isna(tags):\n",
        "            return ''\n",
        "\n",
        "        # Remove brackets if present\n",
        "        if tags.startswith('[') and tags.endswith(']'):\n",
        "            tags = tags[1:-1]\n",
        "\n",
        "        # Split by common delimiters and clean\n",
        "        tag_list = re.split(r'[,|;]', tags)\n",
        "        tag_list = [tag.strip().lower() for tag in tag_list if tag.strip()]\n",
        "\n",
        "        return ' '.join(tag_list)\n",
        "\n",
        "print(\"\\nPreprocessing data...\")\n",
        "text_processor = TextPreprocessor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6gl9Ct3CFhP",
        "outputId": "699f1ec3-636d-4bf6-a047-f4734aa015ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('corpus')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdaY9CD0CP89"
      },
      "outputs": [],
      "source": [
        "# Function to predict trending potential and provide recommendations\n",
        "def predict_trending_potential(title, description, tags):\n",
        "    if not title:\n",
        "        print(\"No Title - 0% Chance to Trend\")\n",
        "        print(\"\")\n",
        "        print(\"Recommendations :\")\n",
        "        print(\"Consider making your title longer (at least 40 characters).\")\n",
        "        return\n",
        "\n",
        "    else:\n",
        "\n",
        "      # Load saved models and vectorizers\n",
        "      model = joblib.load('/content/drive/MyDrive/best_model.pkl')\n",
        "      tfidf_title = joblib.load('/content/drive/MyDrive/tfidf_title.pkl')\n",
        "      tfidf_description = joblib.load('/content/drive/MyDrive/tfidf_description.pkl')\n",
        "      tfidf_tags = joblib.load('/content/drive/MyDrive/tfidf_tags.pkl')\n",
        "      tfidf_combined = joblib.load('/content/drive/MyDrive/tfidf_combined.pkl')\n",
        "      text_processor = joblib.load('/content/drive/MyDrive/text_processor.pkl')\n",
        "\n",
        "      # Preprocess inputs\n",
        "      clean_title = text_processor.clean_text(title)\n",
        "      clean_description = text_processor.clean_text(description)\n",
        "      clean_tags = text_processor.process_tags(tags)\n",
        "      combined_text = clean_title + ' ' + clean_description + ' ' + clean_tags\n",
        "\n",
        "      # Extract text features\n",
        "      features = {}\n",
        "      features['title_length'] = len(title) if title else 0\n",
        "      features['title_word_count'] = len(clean_title.split()) if clean_title else 0\n",
        "      features['has_description'] = 0 if description in ['[none]', ''] or pd.isna(description) else 1\n",
        "      features['description_length'] = len(description) if description and description != '[none]' and not pd.isna(description) else 0\n",
        "      features['description_word_count'] = len(clean_description.split()) if clean_description else 0\n",
        "      features['has_tags'] = 0 if tags in ['[none]', ''] or pd.isna(tags) else 1\n",
        "      features['tag_count'] = len(re.split(r'[,|;]', tags)) if tags and tags != '[none]' and not pd.isna(tags) else 0\n",
        "      features['title_has_question'] = 1 if '?' in title else 0\n",
        "      features['title_has_exclamation'] = 1 if '!' in title else 0\n",
        "      features['title_starts_with_number'] = 1 if re.match(r'^\\d+', title) else 0\n",
        "      features['title_has_all_caps'] = 1 if any(word.isupper() and len(word) > 1 for word in title.split()) else 0\n",
        "      features['title_has_brackets'] = 1 if ('(' in title and ')' in title) or ('[' in title and ']' in title) else 0\n",
        "\n",
        "      # Transform to vectors\n",
        "      X_title = tfidf_title.transform([clean_title])\n",
        "      X_description = tfidf_description.transform([clean_description])\n",
        "      X_tags = tfidf_tags.transform([clean_tags])\n",
        "      X_combined = tfidf_combined.transform([combined_text])\n",
        "\n",
        "      # Create feature array\n",
        "      X_text_features = np.array(list(features.values())).reshape(1, -1)\n",
        "      X_combined_array = X_combined.toarray()\n",
        "\n",
        "      # Combine features\n",
        "      X = np.hstack((X_text_features, X_combined_array))\n",
        "\n",
        "      # Make prediction\n",
        "      probability = model.predict_proba(X)[0, 1]\n",
        "      percentage = probability * 100\n",
        "\n",
        "      # Generate recommendations\n",
        "      recommendations = []\n",
        "\n",
        "      # Title recommendations\n",
        "      if features['title_length'] < 30:\n",
        "          recommendations.append(\"Consider making your title longer (at least 40 characters).\")\n",
        "      if not features['title_has_question'] and probability < 0.7:\n",
        "          recommendations.append(\"Consider adding a question mark to your title to increase engagement.\")\n",
        "      if not features['title_has_exclamation'] and probability < 0.7:\n",
        "          recommendations.append(\"Consider adding an exclamation mark to make your title more exciting.\")\n",
        "      if not features['title_starts_with_number'] and probability < 0.7:\n",
        "          recommendations.append(\"Consider starting your title with a number (e.g., '5 Ways to...').\")\n",
        "      if not features['title_has_all_caps'] and probability < 0.7:\n",
        "          recommendations.append(\"Consider adding ONE word in ALL CAPS for emphasis.\")\n",
        "\n",
        "      # Description recommendations\n",
        "      if features['description_length'] < 100:\n",
        "          recommendations.append(\"Your description is too short. Aim for at least 200 characters.\")\n",
        "      elif features['description_length'] < 200:\n",
        "          recommendations.append(\"Consider expanding your description with more details.\")\n",
        "\n",
        "      # Tags recommendations\n",
        "      if features['tag_count'] < 5:\n",
        "          recommendations.append(\"Add more tags to increase discoverability. Aim for at least 10 tags.\")\n",
        "      elif features['tag_count'] < 10:\n",
        "          recommendations.append(\"Consider adding more tags to reach the optimal count of 15-20 tags.\")\n",
        "\n",
        "      # Check for trending words\n",
        "      trending_words_dict = dict(trending_words)\n",
        "      title_words = set(clean_title.split())\n",
        "      desc_words = set(clean_description.split())\n",
        "      tag_words = set(clean_tags.split())\n",
        "\n",
        "      all_words = title_words.union(desc_words).union(tag_words)\n",
        "      missing_trending_words = [word for word, ratio in trending_words[:20] if word not in all_words]\n",
        "\n",
        "      if missing_trending_words:\n",
        "          recommendations.append(f\"Consider including some of these high-performing words: {', '.join(missing_trending_words[:5])}\")\n",
        "\n",
        "      # Title length recommendations based on data\n",
        "      avg_trending_title_length = 40  # Replace with actual value from your analysis\n",
        "      if features['title_length'] < avg_trending_title_length * 0.7:\n",
        "          recommendations.append(f\"Your title is shorter than most trending videos. Consider lengthening it to around {avg_trending_title_length} characters.\")\n",
        "      elif features['title_length'] > avg_trending_title_length * 1.5:\n",
        "          recommendations.append(f\"Your title might be too long. Consider shortening it to around {avg_trending_title_length} characters.\")\n",
        "\n",
        "      # Return results\n",
        "      return {\n",
        "          'trending_probability': probability,\n",
        "          'trending_percentage': percentage,\n",
        "          'recommendations': recommendations\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jLH7s0NCUAs",
        "outputId": "ba5662d4-2f99-4fd0-ab9d-051f8b470308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Example:\n",
            "Title: 10 Amazing Facts About Space You Won't Believe!\n",
            "Description: In this video, we explore the most fascinating and mind-blowing facts about our universe that most people don't know. From black holes to distant galaxies, prepare to have your mind blown!\n",
            "Tags: space, universe, astronomy, facts, amazing, science, education, blackhole\n",
            "Trending Probability: 0.8499\n",
            "Trending Percentage: 84.99%\n",
            "\n",
            "Recommendations:\n",
            "1. Consider expanding your description with more details.\n",
            "2. Consider adding more tags to reach the optimal count of 15-20 tags.\n",
            "3. Consider including some of these high-performing words: goo, google, jimmy, punjabi, late\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "trending_words = [('goo', 12.879195145493743), ('google', 10.263471237548654), ('jimmy', 8.54731531915323), ('punjabi', 7.401170038109182), ('late', 7.346954547179068), ('star', 6.872629479757715), ('2018\"', 6.8162734646580505), ('list', 5.950030840021772), ('facebook', 5.719230899477845), ('bit', 5.646139900219482), ('twitter', 5.493023020752765), ('show\"', 5.328208914436512), ('dubbed', 5.046648316156261), ('telugu', 4.789440307339502), ('celebrity', 4.682535718809587), ('director', 4.362665665779235), ('itunes', 4.25467170443928), ('producer', 4.1810224422202005), ('\"punjabi', 4.123725802308281), ('movies\"', 4.116880692213481), ('comedy\"', 4.022820361183379), ('show', 3.9117611445681164), ('\"telugu', 3.8792548012889316), ('production', 3.865690347846606), ('com', 3.606691947979348), ('playlist', 3.4739099124808055), ('videos\"', 3.429145771353231), ('singh', 3.370740634054742), ('\"comedy', 3.286671475013391), ('www', 3.2794115379011965), ('vijay', 3.249725274899692), ('\"amit', 3.205696011861368), ('talk', 3.143498052796781), ('nbc', 3.1138312903274303), ('user', 3.04694109040745), ('starring', 3.0314305961590726), ('comedy', 3.014006804610808), ('film', 2.982351704420323), ('plus', 2.925764138623556), ('interview', 2.886233525855246), ('sun', 2.868552366153559), ('bucket', 2.847505833240214), ('south', 2.8457364243672356), ('entertainment', 2.7721232933475566), ('christmas', 2.7309459307013904), ('apps', 2.670345634703313), ('latest', 2.6503051581701578), ('interview\"', 2.6432446637209), ('\"desi', 2.6381906586277437), ('soundcloud', 2.621086445751337)]\n",
        "\n",
        "print(\"\\nPrediction Example:\")\n",
        "sample_title = \"10 Amazing Facts About Space You Won't Believe!\"\n",
        "sample_description = \"In this video, we explore the most fascinating and mind-blowing facts about our universe that most people don't know. From black holes to distant galaxies, prepare to have your mind blown!\"\n",
        "sample_tags = \"space, universe, astronomy, facts, amazing, science, education, blackhole\"\n",
        "\n",
        "prediction = predict_trending_potential(sample_title, sample_description, sample_tags)\n",
        "\n",
        "if not sample_title:\n",
        "    print(\"\")\n",
        "else:\n",
        "  print(f\"Title: {sample_title}\")\n",
        "  print(f\"Description: {sample_description}\")\n",
        "  print(f\"Tags: {sample_tags}\")\n",
        "  print(f\"Trending Probability: {prediction['trending_probability']:.4f}\")\n",
        "  print(f\"Trending Percentage: {prediction['trending_percentage']:.2f}%\")\n",
        "  print(\"\\nRecommendations:\")\n",
        "  for i, rec in enumerate(prediction['recommendations'], 1):\n",
        "      print(f\"{i}. {rec}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bdWzm3JCXqT",
        "outputId": "6d8d96a5-1d5e-4d7f-bd82-fafbde6f8c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Example:\n",
            "Title: Top 10 Hacks\n",
            "Description: These are the top 10 hacks which are never shown by anyone\n",
            "Tags: Top10, Hacks, New, Technology, Phone\n",
            "Trending Probability: 0.3352\n",
            "Trending Percentage: 33.52%\n",
            "\n",
            "Recommendations:\n",
            "1. Consider making your title longer (at least 40 characters).\n",
            "2. Consider adding a question mark to your title to increase engagement.\n",
            "3. Consider adding an exclamation mark to make your title more exciting.\n",
            "4. Consider starting your title with a number (e.g., '5 Ways to...').\n",
            "5. Consider adding ONE word in ALL CAPS for emphasis.\n",
            "6. Your description is too short. Aim for at least 200 characters.\n",
            "7. Consider adding more tags to reach the optimal count of 15-20 tags.\n",
            "8. Consider including some of these high-performing words: goo, google, jimmy, punjabi, late\n",
            "9. Your title is shorter than most trending videos. Consider lengthening it to around 40 characters.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "print(\"\\nPrediction Example:\")\n",
        "sample_title = \"Top 10 Hacks\"\n",
        "sample_description = \"These are the top 10 hacks which are never shown by anyone\"\n",
        "sample_tags = \"Top10, Hacks, New, Technology, Phone\"\n",
        "\n",
        "prediction = predict_trending_potential(sample_title, sample_description, sample_tags)\n",
        "\n",
        "if not sample_title:\n",
        "    print(\"\")\n",
        "else:\n",
        "  print(f\"Title: {sample_title}\")\n",
        "  print(f\"Description: {sample_description}\")\n",
        "  print(f\"Tags: {sample_tags}\")\n",
        "  print(f\"Trending Probability: {prediction['trending_probability']:.4f}\")\n",
        "  print(f\"Trending Percentage: {prediction['trending_percentage']:.2f}%\")\n",
        "  print(\"\\nRecommendations:\")\n",
        "  for i, rec in enumerate(prediction['recommendations'], 1):\n",
        "      print(f\"{i}. {rec}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBfSXx_ZCZWy",
        "outputId": "760d0790-57ab-4054-89a9-52c5abdd9fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Example:\n",
            "No Title - 0% Chance to Trend\n",
            "\n",
            "Recommendations :\n",
            "Consider making your title longer (at least 40 characters).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "print(\"\\nPrediction Example:\")\n",
        "sample_title = \"\"\n",
        "sample_description = \"\"\n",
        "sample_tags = \"\"\n",
        "\n",
        "prediction = predict_trending_potential(sample_title, sample_description, sample_tags)\n",
        "\n",
        "if not sample_title:\n",
        "    print(\"\")\n",
        "else:\n",
        "  print(f\"Title: {sample_title}\")\n",
        "  print(f\"Description: {sample_description}\")\n",
        "  print(f\"Tags: {sample_tags}\")\n",
        "  print(f\"Trending Probability: {prediction['trending_probability']:.4f}\")\n",
        "  print(f\"Trending Percentage: {prediction['trending_percentage']:.2f}%\")\n",
        "  print(\"\\nRecommendations:\")\n",
        "  for i, rec in enumerate(prediction['recommendations'], 1):\n",
        "      print(f\"{i}. {rec}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}